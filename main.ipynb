{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Data & "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import networkx as nx\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Open the files and store them as dataframes, data must be inserted into data file\n",
    "dfMenu = pd.read_csv(\"data/Menu.csv\")\n",
    "dfMenuPage = pd.read_csv(\"data/MenuPage.csv\")\n",
    "dfMenuItem = pd.read_csv(\"data/MenuItem.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleaning the Data\n",
    "Only 100 sponsors are in the dictionary due to the large size of the files. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "menuDict = {} #create empty dict\n",
    "\n",
    "for index, row in dfMenu.iterrows(): #iterate through the rows\n",
    "    menuId = row[0] #save the Menu ID\n",
    "    sponsor = row[2] #save the sponsor name\n",
    "    \n",
    "    #break if the length of the dictionary is 100\n",
    "    if len(menuDict) == 100:\n",
    "        break\n",
    "    \n",
    "    if re.search(r'\\bDINNER\\b', str(row[3])): #use regex to find when dinner is stated in the event row\n",
    "        dishList = [] #create empty list to store dishes\n",
    "        #find the ids(which is menu_page_id in MenuItem.csv) at the menuID for this individual menu\n",
    "        seriesPageID = dfMenuPage.query(f'menu_id == {menuId}')['id']\n",
    "\n",
    "        #for each menupage ID...\n",
    "        for menuPageID in seriesPageID:\n",
    "            seriesDishID = dfMenuItem.query(f'menu_page_id == {menuPageID}')['dish_id'].dropna() #...find the item IDs for each menuPageID and drop NaN values\n",
    "            \n",
    "            #find each dishID\n",
    "            for dishID in seriesDishID:\n",
    "                \n",
    "                dishList.append(int(dishID)) #append the dish to the dish list\n",
    "\n",
    "        #add the dish to the dictionary, making sure to append if it already exists\n",
    "        if sponsor in menuDict:\n",
    "            menuDict[sponsor] += dishList\n",
    "        else:   \n",
    "            menuDict[sponsor] = dishList"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating the network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = nx.Graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for sponsor1, dishID1 in menuDict.items():\n",
    "    print(sponsor1)\n",
    "    print(dishID1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for sponsor in menuDict:\n",
    "    \n",
    "    #Create a node for every sponsor\n",
    "    g.add_node(str(sponsor))\n",
    "    \n",
    "    i=0\n",
    "    menuItems = list(menuDict.items())\n",
    "    \n",
    "    #double iterate through the sponsors and dishes\n",
    "    for sponsor1, dishlist1 in menuItems:\n",
    "        for sponsor2, dishlist2 in menuItems[i+1:]:\n",
    "            \n",
    "            #double iterate throush the dish lists\n",
    "            for dishID1 in dishlist1:\n",
    "                for dishID2 in dishlist2:\n",
    "                #print(commonDish)\n",
    "                #get current weight if it exits\n",
    "                    if dishID1 == dishID2:\n",
    "                        current_weight = g.get_edge_data(str(sponsor1), str(sponsor2), default={\"weight\": \"0\"})[\"weight\"]\n",
    "                        \n",
    "                        #add an edge\n",
    "                        g.add_edge(str(sponsor1), str(sponsor2), weight=int(current_weight)+1)\n",
    "                \n",
    "        i += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Print the number of nodes and edges, useful for double-checking, especially to make sure the graph is imported correctly into Gephi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Number of nodes:\", len(g.nodes))\n",
    "print(\"Number of edges:\", len(g.edges))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write the graph. File can be opened with Gephi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Write the graph for viewing\n",
    "nx.write_graphml(g, \"menu.graphml\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate the top and bottom three for Degree of Centrality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate degree centrality for all nodes\n",
    "centrality_degree = nx.degree_centrality(g)\n",
    "\n",
    "# sort node-centrality dictionary by metric, and reverse to get top elements first\n",
    "i=1\n",
    "for u in sorted(centrality_degree, key=centrality_degree.get, reverse=True)[:3]:\n",
    "    print(f\"{i}. {u} has a centrality of {centrality_degree[u]}\")\n",
    "    i+=1\n",
    "\n",
    "print(\"===================================================\")\n",
    "\n",
    "# sort node-centrality dictionary by metric to get bottom elements.\n",
    "i=1\n",
    "for u in sorted(centrality_degree, key=centrality_degree.get)[:3]:\n",
    "    print(f\"{i}. {u} has a centrality of {centrality_degree[u]}\")\n",
    "    i+=1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bias check, read medium post for more information about this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Length: {len(menuDict['CUNARD LINE'])}\")\n",
    "print(f\"Length: {len(menuDict['HOTEL SAVOY'])}\")\n",
    "print(f\"Length: {len(menuDict['MAXWELL HOUSE'])}\")\n",
    "\n",
    "print(\"===================================================\")\n",
    "\n",
    "print(f\"Length: {len(menuDict['MR. S.R.BLOOMFIELD'])}\")\n",
    "amerique = 'LEGATION DES ETAT-UNIS D\\'AMERIQUE'\n",
    "print(f\"Length: {len(menuDict[amerique])}\")\n",
    "print(f\"Length: {len(menuDict['TIMEO HOTEL'])}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
